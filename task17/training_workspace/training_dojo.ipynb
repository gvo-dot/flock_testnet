{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d190978-d7bc-4b30-a1cd-18384868fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "TASK_ID=\"17\"\n",
    "FLOCK_API_KEY=None\n",
    "HF_TOKEN=None\n",
    "CUDA_VISIBLE_DEVICES=\"0\"\n",
    "HF_USERNAME=None\n",
    "keys = {}\n",
    "\n",
    "with open(\"../../key.json\", \"r\") as fp:\n",
    "    keys = json.load(fp)\n",
    "\n",
    "os.environ[\"TASK_ID\"] = TASK_ID\n",
    "os.environ[\"FLOCK_API_KEY\"] = keys.get(\"FLOCK_API_KEY\", FLOCK_API_KEY)\n",
    "os.environ[\"HF_TOKEN\"] = keys.get(\"HF_TOKEN\", HF_TOKEN)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = keys.get(\"CUDA_VISIBLE_DEVICES\", CUDA_VISIBLE_DEVICES) \n",
    "os.environ[\"HF_USERNAME\"] = keys.get(\"HF_USERNAME\", HF_USERNAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7700a3-c171-47fc-9e4a-3d4b771baecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# the mock-0.3.1 dir contains testcase.py, testutils.py & mock.py\n",
    "sys.path.append('../training_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a89d94-8574-4416-99e3-49f204ba2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import yaml\n",
    "from loguru import logger\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "#from demo import LoraTrainingArguments, train_lora\n",
    "from full_automation import training_automation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e11e7c5-d4b9-401d-81d7-043b0bd6c0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Qwen/Qwen1.5-0.5B': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 1, 'lora_rank': 8, 'lora_alpha': 16, 'lora_dropout': 0.1, 'learning_rate': 0.0001, 'warmup_steps': 20}}, {'Qwen/Qwen1.5-1.8B': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 1, 'lora_rank': 8, 'lora_alpha': 16, 'lora_dropout': 0.1, 'learning_rate': 0.0001, 'warmup_steps': 20}}, {'google/gemma-2b': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 1, 'lora_rank': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'learning_rate': 0.0001, 'warmup_steps': 20}}]\n"
     ]
    }
   ],
   "source": [
    "task_id = os.environ[\"TASK_ID\"]\n",
    "# load trainin args\n",
    "# define the path of the current file\n",
    "# traing_arg_file = 'training_args-yifan_singlemodel-qwen2.yaml'\n",
    "# traing_arg_file = 'training_args-yifan_singlemodel-learningrate-mistral.yaml'\n",
    "traing_arg_file = 'training_args.yaml'\n",
    "\n",
    "\n",
    "\n",
    "with open(traing_arg_file, \"r\") as f:\n",
    "    all_training_args_as_list = yaml.safe_load(f)\n",
    "\n",
    "print(all_training_args_as_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947989fd-8f73-4a70-bf85-0803acd0a7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Qwen/Qwen1.5-0.5B': {'per_device_train_batch_size': 1,\n",
       "   'gradient_accumulation_steps': 8,\n",
       "   'num_train_epochs': 1,\n",
       "   'lora_rank': 8,\n",
       "   'lora_alpha': 16,\n",
       "   'lora_dropout': 0.1,\n",
       "   'learning_rate': 0.0001,\n",
       "   'warmup_steps': 20}},\n",
       " {'Qwen/Qwen1.5-1.8B': {'per_device_train_batch_size': 1,\n",
       "   'gradient_accumulation_steps': 8,\n",
       "   'num_train_epochs': 1,\n",
       "   'lora_rank': 8,\n",
       "   'lora_alpha': 16,\n",
       "   'lora_dropout': 0.1,\n",
       "   'learning_rate': 0.0001,\n",
       "   'warmup_steps': 20}},\n",
       " {'google/gemma-2b': {'per_device_train_batch_size': 1,\n",
       "   'gradient_accumulation_steps': 8,\n",
       "   'num_train_epochs': 1,\n",
       "   'lora_rank': 8,\n",
       "   'lora_alpha': 16,\n",
       "   'lora_dropout': 0.05,\n",
       "   'learning_rate': 0.0001,\n",
       "   'warmup_steps': 20}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_training_args_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65475913-c2c9-4762-9f29-4f6dbfc780ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id='mistralai/Mistral-7B-v0.3'\n",
    "\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#         model_id,\n",
    "#         use_fast=True,\n",
    "#         #padding_side='left',\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa295080-dbca-4bc4-a0a2-8a675b4879b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.special_tokens_map)\n",
    "# print(tokenizer.unk_token)\n",
    "# print(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce2d0cf-b710-498d-aacb-45503c1c3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataset import SFTDataCollator, SFTDataset\n",
    "# from utils.constants import model2template\n",
    "# from train_lora import LoraTrainingArguments, train_lora\n",
    "# from utils.constants import model2base_model, model2size\n",
    "# from utils.flock_api import get_task, submit_task\n",
    "\n",
    "# task = get_task(task_id)\n",
    "# max_params = task[\"data\"][\"max_params\"]\n",
    "# context_length = task[\"data\"][\"context_length\"]\n",
    "\n",
    "# dataset = SFTDataset(\n",
    "#         file=\"demo_data_out2.jsonl\",\n",
    "#         tokenizer=tokenizer,\n",
    "#         max_seq_length=context_length,\n",
    "#         template=model2template[model_id],\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ffe9432-0def-47df-ad46-60cdb3ab5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hg_repo_id_list = training_automation(task_id=TASK_ID, \n",
    "#                                       training_args=all_training_args_as_list, \n",
    "#                                       training_data_path=\"demo_data.jsonl\", \n",
    "#                                       dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e4af53c-0ce4-4470-adb0-93da68647a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hg_repo_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45fa70c-3a24-4c4d-b55a-f65676051ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 23:02:26.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mcheck_training_parameter\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mmax model size: {'Qwen/Qwen1.5-0.5B': 620000000, 'Qwen/Qwen1.5-1.8B': 1840000000, 'google/gemma-2b': 2510000000}\u001b[0m\n",
      "\u001b[32m2024-12-08 23:02:26.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mcheck_training_parameter\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mmodel id: Qwen/Qwen1.5-0.5B\u001b[0m\n",
      "\u001b[32m2024-12-08 23:02:26.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mcheck_training_parameter\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mmodel id: Qwen/Qwen1.5-1.8B\u001b[0m\n",
      "\u001b[32m2024-12-08 23:02:26.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mcheck_training_parameter\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mmodel id: google/gemma-2b\u001b[0m\n",
      "\u001b[32m2024-12-08 23:02:26.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mStart to train the model Qwen/Qwen1.5-0.5B...\u001b[0m\n",
      "\u001b[32m2024-12-08 23:02:30.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mLoading data: demo_data.jsonl\u001b[0m\n",
      "\u001b[32m2024-12-08 23:02:30.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mThere are 624 data in dataset\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 01:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.936200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.631600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 23:04:26.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mStart to push the lora weight to the hub...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c11f1491b84d8b9b9aa476f46b3bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb7e2435a0348098d2d112cf6e42018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d12c046b2754ddb818a958789cfa3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/3.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8547a13db74d4e9c69c44e48ce7239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 23:04:31.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mCommit hash: c778328c2685a53e431d0670c8513fdd5bfdaaaa\u001b[0m\n",
      "\u001b[32m2024-12-08 23:04:31.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mRepo name: yifanxie/task-17-Qwen-Qwen1.5-0.5B-1733699066\u001b[0m\n",
      "\u001b[32m2024-12-08 23:04:31.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mTask submitted successfully\u001b[0m\n",
      "\u001b[32m2024-12-08 23:04:32.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mStart to train the model Qwen/Qwen1.5-1.8B...\u001b[0m\n",
      "\u001b[32m2024-12-08 23:04:36.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mLoading data: demo_data.jsonl\u001b[0m\n",
      "\u001b[32m2024-12-08 23:04:36.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mThere are 624 data in dataset\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 04:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.820900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.477800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.333900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 23:08:52.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mStart to push the lora weight to the hub...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259dbc0422724e6ba53fb915b15e1760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/6.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cad175023b4e049b5bf78615ed4e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2305412c32c74048af859d10de909548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a8d9487377439cbc280db0d81f0ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 23:08:57.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mCommit hash: 74fa033ab5280eb9f9430466e9714da63c510ef4\u001b[0m\n",
      "\u001b[32m2024-12-08 23:08:57.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mRepo name: yifanxie/task-17-Qwen-Qwen1.5-1.8B-1733699332\u001b[0m\n",
      "\u001b[32m2024-12-08 23:08:58.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mTask submitted successfully\u001b[0m\n",
      "\u001b[32m2024-12-08 23:08:58.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mStart to train the model google/gemma-2b...\u001b[0m\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac49186197d48788f130ceab636bbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 23:09:04.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mLoading data: demo_data.jsonl\u001b[0m\n",
      "\u001b[32m2024-12-08 23:09:04.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mThere are 624 data in dataset\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 03:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.988800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 23:12:13.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mStart to push the lora weight to the hub...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67a7228576347a4af7796f47a3dd39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/3.70M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fe42ae105842c6b92b90933785c3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e40e80cca24a3a87c3393f2e8f4ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2508f2f3ede4460a90abe85e1ec6a420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44864b6d059f49e6a069bbc82e29c75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 23:12:19.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mCommit hash: c7576544b66c7c6d9f223dc2b1ac16b564e757f6\u001b[0m\n",
      "\u001b[32m2024-12-08 23:12:19.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mRepo name: yifanxie/task-17-google-gemma-2b-1733699533\u001b[0m\n",
      "\u001b[32m2024-12-08 23:12:19.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfull_automation\u001b[0m:\u001b[36mtraining_automation\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mTask submitted successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "hg_repo_id_list = training_automation(task_id=TASK_ID, \n",
    "                                      training_args=all_training_args_as_list, \n",
    "                                      training_data_path=\"demo_data.jsonl\", \n",
    "                                      dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61863f4a-047c-4c9d-8ec5-882ab01af54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
