- Qwen/Qwen1.5-7B:
    per_device_train_batch_size: 1
    gradient_accumulation_steps: 8
    num_train_epochs: 3
    lora_rank: 8
    lora_alpha: 16
    lora_dropout: 0.1
    learning_rate: 1.0e-4
    warmup_steps: 20